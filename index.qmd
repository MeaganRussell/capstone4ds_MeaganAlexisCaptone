---
title: "Predicting Flood Severity of Northwest Florida Counties using Random Forest Regression Modeling - Spring 2026 "
author: "Meagan Russell (Advisor: Dr. Cohen)"
date: last-modified
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---
<!--

This is for me later, once the slides are ready to go.

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)
-->

## Week 1 - Individual Research:

**Paper One: Random Forest Algorithm Overview**

This paper provides an overview of the Random Forest (RF) algorithm. Random Forest is a type of machine learning algorithm that uses a target variable known as a dependent variable. The goal of Random Forest is to predict the dependent variable based on independent variables. The way RF works is by creating decision trees. Decision trees are a series of yes/no questions, for example: 


Did the flooding cause any deaths? 

Did the flooding result in more than $1,000,000 in property damage?

Did the flood occur countywide?

Did the flood cause agricultural damage?


The authors go on to explain how Random Forest is a smart model that uses simple models, decision trees, which each can make small mistakes, but in the end, once all of the simple models are combined, they get the answer right. In addition, each decision tree's selection of data is random, which prevents the model from memorizing the data. There are limitations to Random Forest, such as increased computational cost and reduced transparency; however, overall Random Forest is reliable, widely applicable, and suitable for real-world problems.

Cite new paper @Salman2024RandomForest

**Paper two: Machine Learning Classification of Significant Tornadoes and Hail in the United States Using ERA5 Proximity Soundings**

In this paper the authors compared logistic regression, gaussian naive bayes, support vector machines, decision trees, adaptive boosting, gradient boosting, and random forest classification to see which model could best predict the severity class of tornadoes and hail events (severe vs. significant-severe). The data used in this study was collected from two sources: ERA5 for the weather and climate and NOAA for the actual storm events. The goal was to predict the severity of the storms with the weather and climate data before known events. To test the models the authors used validation techniques, multiple skill metrics, and frequency. For instance, the authors tested the models by leaving one year out for cross validation and they evaluated model performance using the critical success index (CSI). Of the models used, Random Forest, was the best model. It was the most accurate and it didn't over or under estimate the severity of the storms. The authors also state that Random Forest can potentially be used for real-world forecasting applications.

Cite new paper @Gensini2021SevereML
